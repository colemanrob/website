[{"content":"I work at the intersection of data science and labour market policy. I studied political science and economics and now I spend a lot of time analyzing data using #rstats and building things on the web.\n","href":"/","title":"Home"},{"content":"I write notes on research relating to active labour market policies, and summarize the most useful insights\n","href":"/notes/","title":"Notes"},{"content":"I write notes about how to solve problems using #rstats, a free open-source programming language for data science.\n","href":"/post/","title":"Code"},{"content":"I try to keep track of what I read, especially when I come across an interesting idea. Always interested in suggestions.\n","href":"/books/","title":"Books"},{"content":"Hi, I\u0026rsquo;m Rob üòÑ\nI work in government at the intersection of data science and active labour market policy. I studied political science and economics. Now I spend a lot of time analyzing data using #rstats and building things on the web.\nI live in the Canadian north with my partner and this guy:\n   View this post on Instagram        Barn yard!\nA post shared by Rob (@robcoleman) on Aug 24, 2017 at 3:04pm PDT\n  ","href":"/about/","title":"About"},{"content":"","href":"/tags/almps/","title":"ALMPs"},{"content":" Rodrigo Fernandezi, Herwig Immervolli, Daniele Pacificoi and C√©line Th√©venoti, 2016\n this research advances new methods to categorize employment barriers among jobseekers so as to design appropriately tailored activation responses across policy and institutional domains. little is known about specific employment barriers at the individual level, instead broad proxies are used to describe populations (NEET, older workers etc) instead the authors try a bottom up approach by categorizing and measuring employment barriers using latest class analysis (LDA), a clustering method, the authors find more useful groups of jobseekers who share common employment barriers by analyzing the European Union Statisitcs on Income and Living Conditions (EU SILC) available here  Types of Employment Barriers  lack of work-relateed capabilities  a range of factors that may limit an individuals\u0026rsquo; capacity to perform a specific task (e.g. lack of educations, skills or work experience, care responsibilities, or health limitations)  lack of work incentives  weak incentives to look for or accept a good job - (e.g. low pay, generous out of work benefits)  lack of employment opportunities (regional)  a small number of vacancies in the labour market segment due to information asymmetries, skills mismatches, discrimination   ","href":"/notes/emp-barriers/","title":"Notes on employment barriers"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/tags/activation/","title":"activation"},{"content":"","href":"/tags/barriers/","title":"barriers"},{"content":" Sources  Student\u0026rsquo;s Guide to Bayesian Statisitcs, Ben Lambert Statistical Rethinking, Richard McElreath Probability Theory: The Logic of Science, E.T. Jaynes  Part 1 Statistical Inference  sometimes we know the process that generates data (e.g. coin-flip) and so calculating probability is straightforward. when we don\u0026rsquo;t have perfect knowledge of the process; it is the goal of statistical inference to derive estimates of unknown characteristics or parameters of these data-generating mechanisms. Bayesians start with what is known - the data - and make probabilistic assumptions about the underlying process that generates the data. statistical inference is the logical framwork used to trial our beliefs about the noisy world with data. We formalize our beliefs with models of probability.  Bayes Theorem $$ p(\\theta | data) = {p(data | \\theta) \\cdot p(\\theta) \\over p(data)} $$\nNote: this post will be updated as I work through the source materials\nLast Updated: June 24, 2019\n","href":"/books/bayes/","title":"Notes on Bayesian Statistics"},{"content":"","href":"/tags/bayes/","title":"bayes"},{"content":" 2019    Title Author Rating     Measures of Success: React Less, Lead Better, Improve More Mark Graban ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Other Minds: The Octopus, the Sea, and the Deep Origins of Consciousness Peter Godfrey-Smith ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Bad Blood: Secrets and Lies in a Silicon Valley Startup John Carreyrou ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Beginning of Infinity: Explanations That Transform the World David Deutsch ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Future Babble: Why Expert Predictions Fail - and Why We Believe Them Anyway Dan Gardner ‚≠êÔ∏è‚≠êÔ∏è   Better Now: Six Big Ideas to Improve Health Care for All Canadians Danielle Martin ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Just Mercy: A Story of Justice and Redemption Bryan Stevenson ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Black Swan: The Impact of the Highly Improbable Nassim Nicholas Taleb ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è    2018    Title Author Rating     The Great Stagnation: How America Ate All the Low-Hanging Fruit of Modern History, Got Sick, and Will (Eventually) Feel Better Tyler Cowen ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Educated Tara Westover ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Undoing Project: A Friendship That Changed Our Minds Michael Lewis ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Seven Fallen Feathers: Racism, Death, and Hard Truths in a Northern City Tanya Talaga ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Robot-Proof: Higher Education in the Age of Artificial Intelligence Joseph E. Aoun ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Theory That Would Not Die: How Bayes\u0026rsquo; Rule Cracked the Enigma Code, Hunted Down Russian Submarines, and Emerged Triumphant from Two Centuries of Controversy Sharon Bertsch McGrayne ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Superforecasting: The Art and Science of Prediction Philip E. Tetlock ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Complacent Class: The Self-Defeating Quest for the American Dream Tyler Cowen ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   All Our Relations: Finding the Path Forward Tanya Talaga ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Enlightenment Now: The Case for Reason, Science, Humanism, and Progress Steven Pinker ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   Factfulness: Ten Reasons We\u0026rsquo;re Wrong About the World ‚Äì and Why Things Are Better Than You Think Hans Rosling ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è   The Great Escape: Health, Wealth, and the Origins of Inequality Angus Deaton ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è    ","href":"/books/books/","title":"Booklist + ratings update"},{"content":"","href":"/tags/books/","title":"books"},{"content":" I was inspired by David Robinson\u0026rsquo;s latest webcast in which he made a heatmap of French train delays using geom_tile and wanted to try it out for myself.\n In this week\u0026#39;s #tidytuesday screencast, I analyze delays in French train stations üá´üá∑üöÑ\nI show how to create heatmaps of delays (inspired by @noccaea!), and embarrass myself with even the simplest French pronunciationshttps://t.co/zBrkIkdcCz #rstats pic.twitter.com/RI7ZpxV89X\n\u0026mdash; David Robinson (@drob) February 26, 2019  \nI don\u0026rsquo;t have a lot of opportunities to use heatmaps, but recently Statcan has released their Journey to Work data as part of the 2016 Census. I wanted to see if I could use a heatmap to understand the commuting patterns in communities in southern Ontario.\nLoad packages library(tidyverse) library(cancensus) I downloaded the commuting table from statscan because I couldn\u0026rsquo;t find it using the cancensus package.\nraw_commute \u0026lt;- read_csv(\u0026#34;~/projects/R stuff/commute/98-400-X2016391_English_CSV_data.csv\u0026#34;) %\u0026gt;% janitor::clean_names() %\u0026gt;% select(code = geo_code_por, live = geo_name, work = geo_name_1, total = dim_sex_3_member_id_1_total_sex)# filter only those whose code starts w/ 35 (Ontario) ontario_commute \u0026lt;- raw_commute %\u0026gt;% filter(str_detect(code, pattern = \u0026#34;^35\u0026#34;))  Download geography data I was able to retrieve the working age population and census division geographies using cancensus\nlibrary(cancensus) library(sf) ## Linking to GEOS 3.7.0, GDAL 2.3.2, PROJ 5.2.0  # create list of ontario census divisions to pass to cancensus regions_list_ontario \u0026lt;- list_census_regions(\u0026#34;CA16\u0026#34;) %\u0026gt;% filter(str_detect(region, pattern = \u0026#34;^35\u0026#34;)) %\u0026gt;% as_census_region_list ## Querying CensusMapper API for regions data...  pop_data \u0026lt;- get_census(\u0026#34;CA16\u0026#34;, regions = regions_list_ontario, vectors = \u0026#34;v_CA16_61\u0026#34;, level = \u0026#34;CD\u0026#34;, geo_format = \u0026#34;sf\u0026#34;, labels = \u0026#34;short\u0026#34;) %\u0026gt;% janitor::clean_names()# clean pop_data %\u0026gt;% mutate(working_age = v_ca16_61) %\u0026gt;% mutate(code = as.double(geo_uid)) %\u0026gt;% select(code, working_age, shape_area, geometry) -\u0026gt; pop_data_clean Joining the tables together # remove commuting within cd, compute totals ontario_commute %\u0026gt;% filter(live != work) %\u0026gt;% group_by(live) %\u0026gt;% mutate(total_commuters = sum(total), prop_commuters = total / total_commuters ) %\u0026gt;% ungroup() %\u0026gt;% left_join(pop_data_clean, by = \u0026#34;code\u0026#34;) %\u0026gt;% group_by(work) %\u0026gt;% mutate(total_commuters_destination = sum(total)) %\u0026gt;% mutate(live_prop = total_commuters / working_age, work_prop = total / working_age ) %\u0026gt;% ungroup() -\u0026gt; ontario_commute_clean Create visualizations Let\u0026rsquo;s see what visualizations will work.\nontario_commute_clean %\u0026gt;% filter(total \u0026gt;= 3000) %\u0026gt;% mutate(live = str_wrap(live, width = 15)) %\u0026gt;% mutate(live = fct_reorder(live, total)) %\u0026gt;% mutate(work = fct_reorder(work, total)) %\u0026gt;% ggplot(aes(live, work, fill = total)) + geom_tile(alpha = 0.7) + theme_light() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_fill_viridis_c(labels = scales::comma_format()) + labs(fill = \u0026#34;# of commuters\u0026#34;, title = \u0026#34;The largest number of commuters in Ontario are those who live in York, Peel and Durham who commute to Toronto for work\u0026#34;, subtitle = \u0026#34;Number of employed labour force aged 15+ who commute by Census Division - Minimum 3,000 commuters to be represented\u0026#34;, x = \u0026#34;Live - Census Division\u0026#34;, y = \u0026#34;Work - Census Division\u0026#34;, caption = \u0026#34;Data from Statistics Canada 2016 Canadian Census - Journey to Work \\n https://www12.statcan.gc.ca/census-recensement/2016/rt-td/jtw-ddt-eng.cfm\u0026#34;) Map the proportions I\u0026rsquo;m always trying to improve my mapping skills and geom_sf makes it a lot easier.\nontario_commute_clean %\u0026gt;% filter((!live %in% c(\u0026#34;Rainy River\u0026#34;, \u0026#34;Kenora\u0026#34;, \u0026#34;Thunder Bay\u0026#34;, \u0026#34;Algoma\u0026#34;, \u0026#34;Nipissing\u0026#34;, \u0026#34;Cochrane\u0026#34;, \u0026#34;Greater Sudbury / Grand Sudbury\u0026#34;, \u0026#34;Manitoulin\u0026#34;, \u0026#34;Timiskaming\u0026#34;, \u0026#34;Sudbury\u0026#34;, \u0026#34;Parry Sound\u0026#34;))) %\u0026gt;% ggplot() + geom_sf(aes(fill = live_prop)) + scale_fill_viridis_c(\u0026#34;% Labour force who commute to work\u0026#34;, labels = scales::percent) + theme_minimal() + theme(panel.grid = element_blank(), axis.text = element_blank(), axis.ticks = element_blank()) + coord_sf(datum=NA) + labs(title = \u0026#34;The % of the labour force (aged 15+) who commute by Census Division in Southern Ontario\u0026#34;) ","href":"/post/commute/","title":"Analyzing Commuting Patterns in Ontario"},{"content":"","href":"/tags/census/","title":"Census"},{"content":"","href":"/tags/open-data/","title":"Open Data"},{"content":"","href":"/tags/commute/","title":"commute"},{"content":" Moral hazard in ALMPs Bruttel, Oliver 2005\n This research reviews the mechanisms by which government can manage the risks (moral hazard) associated with contracting out of ALMPs using a principal-agent theory lens. the author solves for the risks by advancing an integrated governance approach using 3 distinct governance mechanisms  incentives information control  reviews 3 countries (UK, Netherlands, Australia)  Principal-agent theory and moral hazard  concerned with how does govt (principal) ensure that service providers (agents) act in the govts interest main risk is moral hazard where agents act in their own interest (maximising utility, risk avoidance etc) where principal cannot observe their actions moral hazard in ALMPs revolve around 3 key areas:  creaming - selecting only optimal clients for service parking - not serving clients with low success probability dead-weight - serving clients who would have otherwise been successful without intervention (not explicitly mentioned but described elsewhere)   1. Incentive mechanisms  outcomes-based payments split-fee works best (fixed \u0026amp; outcomes) rather than threshold based (like US) so that award function is linear measured as outputs (outcomes at 13 and 26 weeks are standard) rather than inputs (clients served) should optimize around under-investment i.e. skills training like Job Seeker Account (matching govt investment) common strategy to avoid moral hazard problems is to organize outcomes payments by client groups based on assessment tool (e.g. JSCI in AUS and Kansmeter in Netherlands)  2 . Information mechanisms  benchmarking - measure relative performance of providers  2 types of variables: context (regional/local labour market) and jobseeker characteristics (age, duration of unemployment, skills etc) Australia 5 Star model gold standard - best 60% of providers are offered contract renewal without tender  monitoring - mix of database inputs and in-person  overcome blackbox problem irregularities flagged automatically   3. Control mechanisms  rules and regulations (guidelines, eligibility, etc) quality management frameworks  set minimum standard of service  tied to monitoring and benchmarking  Special expertise  identifies 3 types of capacities governments need  feasibility assessment capacity - make-or-buy decisions about services Implementation capacity (incentive mechanisms) tenders, selecting providers, negotiate contracts etc evaluation capacity (information and control) - evaluate and monitor the performance of providers   Institutional moral hazard in Australia PES F Vandenbroucke, C Luigjes, 2016\n This research outlines how Austrialia moved from a blackbox approach to contracting out employment services towards a regime of minimum requirements and monitoring\n reforms of the blackbox approach included:\n new tendering processes (see above) 5 Star rating system for providers adjustment of provider responsibilities standardization of work process  relationship between govt \u0026amp; providers has been rocky as flexibility has been reduced\n problems were creaming and parking\n 3 streams of service\n stream A - job competitive stream B - vocational issues stream C - series non-vocational issues via referral  Denmark devolved employment services to municipalities\n Work for the Dole targets long term barriered clients in an attempt to overcome parking (re-vamp of JCP?)\n the KPIs, outcomes based model also includes a bonus if referred to training\n outcomes are based on location, stream and expediency (how fast) clients move to outcomes.\n  ","href":"/notes/moralhazard/","title":"Notes on Moral hazard"},{"content":"","href":"/tags/moral-hazard/","title":"moral hazard"},{"content":"","href":"/tags/principle-agent/","title":"principle-agent"},{"content":"","href":"/tags/risk/","title":"risk"},{"content":" Estimating the Impact of Active Labour Market Programs using Administrative Data and Matching Methods Handouyahia, 2016\n research link using admin data matched to CRA they find that EBSMs have positive effects on employment and earnings  Findings  EBSMs caused gains in employment earnings, incidence of employment (+2.4% first year to +4.4% by fifth year) and reduction of EI benefits after completing SD had most pronounced effect (between $204 and $4,059 higher) SD represents the largest incremental gains  Labour market program efficacy: Evidence from Ontario Works Adams et. al. 2018\n working paper here and cd howe report here how effective are OW ALMPs on two outcomes:  case duration (benefit \u0026lsquo;spell\u0026rsquo; measured in months) probability of returning to OW within 1 or 2 years of exit  this client group has weaker LM attachment and so not perfectly aligned to existing literature on ALMPs accordingly existing canadian work suggests this group is differentially affected by ALMPs  Findings  placement services extend OW spells by 16 months structured job search not having an effect on \u0026lsquo;return\u0026rsquo; training programs (literacy, skills/vocational) does reduce \u0026lsquo;return\u0026rsquo; by 07% year 1 and 1.1% year 2 among all interventions there\u0026rsquo;s a trade-off between short and long term effectiveness  placement means longer spells but reduces P(return) by 7% in year 1 and 10% year 2 structured job search reduces spell by 1.5 - 3 months but doesn\u0026rsquo;t affect P(return) training program alone is more effective in the short-term than assignment to boht training program and structured job-search (implying the interventions aren\u0026rsquo;t additive)   ","href":"/notes/whatworks/","title":"Notes on outcomes in labour market programs"},{"content":"","href":"/tags/social-assistance/","title":"social assistance"},{"content":"  this research evaluates the strictness of rules (eligibility criteria) that govern the receipt of benefits (first-tier/unemployment and second-tier/welfare) across OECD countries they establish what types of eligibility criteria are common across countries they surveyed each OECD country and derived a quantitative policy indicator of eligibility strictness of each scheme they discuss the impacts of the eligibility choices on first and second tier benefits (for Canada, they used Ontario Works) and marginally discuss administrative provisions (how clients interact with administration)  Eligibility Criteria  entitlement conditions: these are the rules set by the feds over which Ontario has little influence (e.g. how many hours of work before claim is established) activity conditions - behavioural requirements that must be met by those who have an established right (\u0026lsquo;entitlement\u0026rsquo;)  availability criteria  availability during ALMP participation (excuse for training/participation) occupational mobility - refuse based on NOC/less pay geography other valid reasons - canada only labour dispute  job-search and reporting criteria  frequency of job-search activity documentation of job-search  sanctions for non-compliance  voluntary resignation / quit refusal of suitable employment repeated refusal of employment refusal of ALMP participation repeated refusal of ALMP participation    First Tier eligibility criteria  job search \u0026amp; reporting criteria vary strongly but availability criteria varies little to none  australia - job search now once a month and Denmark is entirely online Canada among lowest for job-search and reporting requirements   Second Tier criteria  availability criteria represent biggest difference between first and second tier benefit types two types of jurisdictions - 1 where SA clients don\u0026rsquo;t qualify (see Germany) and could be Canada and 2 - where rules are mostly identical - see UK\u0026rsquo;s jobseekers allowance rules are often less strict here to give local authorities more leeway to design appropriate solutions   Insights  warnings and sanctions generally are shown to shorten benefit duration and increase re-employment among those who may expect to incur a sanction (threat effects work) soft constraints like mandatory participation in AMLPs or gradual reductions of benefits levels over time have similar effects to those of harsher instruments like sanctions and dis-entitlements goal is to strengthen incentives to look/prepare for and accept employment and also target those more suitable  Figures ","href":"/notes/almps/","title":"Notes on incentives in labour market programs"},{"content":"Robot Proof: Higher Education in the age of Artificial Intelligence\nJoseph E. Anoun\n A short but well written glimpse into how higher ed will have to adapt given the progress of artificial intelligence and its impact on human work. Anoun mostly follows Harari on the transition of human work but is more an optimist insofar as he thinks there will still be a role for humans alongside machines in the labour market.\n To prepare students for the new world, Anoun articulates his vision of ‚Äòhumanics‚Äô a new set of literacies (data, technological and human literacy) as well as cognitive capacities, i.e. mindsets (systems thinking, entrepreneurship, cultural agility and critical thinking). The literacies form the content and the capacities form the new ways of thinking and adapting.\n ‚Äòhumanics‚Äô is mostly a summation of the ideas coming out of the shift toward lifelong/adult learning, but it doesn‚Äôt offer much to those currently in the labour market who may be affected by disruption, nor policy makers who will need to rethink retraining schemes that support labour market attachment. Interesting and speculative, but I would‚Äôve liked to have seen more data, especially to support the notion that a future labour market would/could be able to provide enough creative jobs given what we know about the current breakdown of skills. From a higher ed perspective, not much in the way of how post-sec institutions could make such a transition given the current institutional arrangements and incentives.\n  Artificial Unintelligence: How computers misunderstand the world\nMeredith Broussard\n Following Cathy O‚ÄôNeil‚Äôs Weapons of Math Destruction, Broussard takes aim at technochauvism - the notion that technology will always provide a better answer to any given problem. Moving beyond a cataloguing of the abuses of poorly applied models, this book recounts the history of computing from Turing to present day machine learning and it‚Äôs clear the author has a great reverence for technology which makes her arguments about the limits of narrow artificial intelligence all the more persuasive.\n I particularly liked how she brought in John Searle‚Äôs critique of the Turing test which points out the difference between interpreting the symbols of language (which machines can do) versus understanding the meaning of language (which remains solely human).\n  Prediction Machines: The Simple Economics of Artificial Intelligence\nAjay Grawal, Joshua Gans, Avi Goldfarb\n What happens when the cost of prediction falls? Prediction machines examines the implications for a mostly business leader audience, but it‚Äôs interesting enough for policy makers and the rest of us. This book is a great example of how to communicate complex ideas in simple form, it even concludes each chapter with a key points section for easy summaries.  ","href":"/books/summer_reading/","title":"Summer reading"},{"content":"","href":"/tags/prediction/","title":"prediction"},{"content":"","href":"/tags/minimum-wage/","title":"Minimum Wage"},{"content":" I covered some interesting changes to minimum wage in my last post. I\u0026rsquo;m trying to build my skills in the mapping department, so I\u0026rsquo;m going to create an interactive map of the communities most affected by the change in minimum wage.\nLoading the data The wage data is collected by the Canadian federal government and published as an open dataset available for download. The data is geographically organized by economic region, so we\u0026rsquo;ll need the shapefile for those boundaries which is also published as an open dataset!\n## Reading layer `ler_000b16a_e' from data source `c:\\Users\\rob\\Documents\\projects\\minwage_map\\map_data' using driver `ESRI Shapefile' ## Simple feature collection with 76 features and 4 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 3689439 ymin: 659338.9 xmax: 9015737 ymax: 5242179 ## epsg (SRID): NA ## proj4string: +proj=lcc +lat_1=49 +lat_2=77 +lat_0=63.390675 +lon_0=-91.86666666666666 +x_0=6200000 +y_0=3000000 +datum=NAD83 +units=m +no_defs  Clean the Wage data The data has a mix of wage types (hourly, annually) from a variety of sources. For my purposes I\u0026rsquo;ll take the median wage for those occupations where it\u0026rsquo;s reported hourly and ignore the annual data.\n# clean data ON_wage_data \u0026lt;- wage_data %\u0026gt;% filter(PROV == \u0026#34;ON\u0026#34;) %\u0026gt;% #filer ON results only filter(`Annual Wage Flag_Salaire annuel` == 0) %\u0026gt;% #remove annual salaries filter(!is.na(`Median wage_Salaire Median`)) %\u0026gt;% #remove occupations with missing data filter(!`ER Code_Code RE` == \u0026#34;ER35\u0026#34;) %\u0026gt;% #remove Ontario total mutate(ERUID = str_sub(`ER Code_Code RE`, start=3L)) # remove ER from ER Code so it can be joined # how many low wage by community ON_wage_prop \u0026lt;- ON_wage_data %\u0026gt;% mutate(low_wage = case_when( `Median wage_Salaire Median` \u0026lt;= 14 ~ 1, TRUE ~ 0 )) %\u0026gt;% # add a low wage indicator group_by(`ERNAME` = `ER Name_Nom RE`, ERUID) %\u0026gt;% summarise(total_occupations = n_distinct(NOC_CNP), total_low_wage = sum(low_wage)) %\u0026gt;% mutate(prop_low_wage = round(total_low_wage / total_occupations * 100)) # compute the proportion of occupations that are low wage # results ON_wage_prop %\u0026gt;% arrange(desc(prop_low_wage)) %\u0026gt;% kable()    ERNAME ERUID total_occupations total_low_wage prop_low_wage     London 3560 242 31 13   Kingston\u0026ndash;Pembroke 3515 194 24 12   Northwest 3595 157 19 12   Muskoka\u0026ndash;Kawarthas 3520 170 18 11   Toronto 3530 396 39 10   Windsor\u0026ndash;Sarnia 3570 222 23 10   Hamilton\u0026ndash;Niagara Peninsula 3550 337 29 9   Northeast 3590 232 22 9   Ottawa 3510 291 26 9   Kitchener\u0026ndash;Waterloo\u0026ndash;Barrie 3540 335 28 8   Stratford\u0026ndash;Bruce Peninsula 3580 143 12 8    Join the data # subset just ontario ERs ON_ERs \u0026lt;- CAN_ERs %\u0026gt;% filter(PRNAME== \u0026#34;Ontario\u0026#34;) #see if it the subset worked plot(ON_ERs) \n#join the data to the boundary file merged_ON \u0026lt;- merge(ON_ERs, ON_wage_prop, by = \u0026#34;ERUID\u0026#34;) #did it work? summary(merged_ON) ## ERUID ERNAME.x PRUID ## 3510 :1 Hamilton--Niagara Peninsula:1 35 :11 ## 3515 :1 Kingston--Pembroke :1 10 : 0 ## 3520 :1 Kitchener--Waterloo--Barrie:1 11 : 0 ## 3530 :1 London :1 12 : 0 ## 3540 :1 Muskoka--Kawarthas :1 13 : 0 ## 3550 :1 Northeast / Nord-est :1 24 : 0 ## (Other):5 (Other) :5 (Other): 0 ## PRNAME ## Ontario :11 ## Alberta : 0 ## British Columbia / Colombie-Britannique : 0 ## Manitoba : 0 ## New Brunswick / Nouveau-Brunswick : 0 ## Newfoundland and Labrador / Terre-Neuve-et-Labrador: 0 ## (Other) : 0 ## ERNAME.y total_occupations total_low_wage prop_low_wage ## Length:11 Min. :143.0 Min. :12.00 Min. : 8.00 ## Class :character 1st Qu.:182.0 1st Qu.:20.50 1st Qu.: 9.00 ## Mode :character Median :232.0 Median :24.00 Median :10.00 ## Mean :247.2 Mean :24.64 Mean :10.09 ## 3rd Qu.:313.0 3rd Qu.:28.50 3rd Qu.:11.50 ## Max. :396.0 Max. :39.00 Max. :13.00 ## ## geometry ## MULTIPOLYGON :11 ## epsg:NA : 0 ## +proj=lcc ...: 0 ## ## ## ##  Build the map When I first started building the map with leaflet I kept getting this error:\nleaflet(merged_ON)  Warning messages: 1: sf layer is not long-lat data 2: sf layer has inconsistent datum (+proj=lcc +lat_1=49 +lat_2=77 +lat_0=63.390675 +lon_0=-91.86666666666666 +x_0=6200000 +y_0=3000000 +datum=NAD83 +units=m +no_defs). Need '+proj=longlat +datum=WGS84'\nI used st_transform to change from datum=NAD83 to datum=WGS84\nnew_ON \u0026lt;- st_transform(merged_ON, \u0026#34;+proj=longlat\u0026#34;, \u0026#34;+datum=WGS84\u0026#34;) That managed to allow me to use leaflet without throwing up an errors.\n# set colours for cloropleth bins \u0026lt;- c(0, 8,10, 11, 12, 13) pal \u0026lt;- colorBin(\u0026#34;YlOrRd\u0026#34;, domain = new_ON$prop_low_wage, bins = bins) # create labels labels \u0026lt;- sprintf( \u0026#34;\u0026lt;strong\u0026gt;%s\u0026lt;/strong\u0026gt;\u0026lt;br/\u0026gt;%d total occupations \u0026lt;br/\u0026gt; %i total low wage occupations\u0026#34;, new_ON$ERNAME.y, new_ON$total_occupations, new_ON$total_low_wage ) %\u0026gt;% lapply(htmltools::HTML) map \u0026lt;- leaflet(new_ON) %\u0026gt;% addTiles() %\u0026gt;% addPolygons(fillColor = ~pal(prop_low_wage), color = \u0026#34;white\u0026#34;, weight = 2, opacity = 1, fillOpacity = 0.55, highlight = highlightOptions( weight = 3, color = \u0026#34;#666\u0026#34;, dashArray = \u0026#34;\u0026#34;, fillOpacity = 0.7, bringToFront = TRUE), label = labels, labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;3px 8px\u0026#34;), textsize = \u0026#34;15px\u0026#34;, direction = \u0026#34;auto\u0026#34;)) %\u0026gt;% addLegend(\u0026#34;topright\u0026#34;, pal = pal, values = ~new_ON$prop_low_wage, title = \u0026#34;% of low wage occupations\u0026#34;, labFormat = labelFormat(prefix = \u0026#34;%\u0026#34;), opacity = 1) Map of Ontario Economic Regions by Low Wage  References  Jesse Sadler\u0026rsquo;s excellent GIS Intro with R The sf package vignette A good discussion on merging spatial data This repo was really helpful Intro to mapping and spatial analysis  ","href":"/post/writeup/","title":"Using Open Data to map Bill 148 effects"},{"content":" Ontario has recently made changes to the minimum wage and many didn\u0026rsquo;t react calmly. I thought it might be interesting to see what kinds of occupations will be affected by the changes. Thankfully, the federal government posted a dataset on wages that helps answer some questions.\nExploring the data We can use the dataset to find out which occupations have a median wage of less than $14/hr. I\u0026rsquo;m particularly interested in my neck of the woods, Northern Ontario. It often demonstrates typical core-periphary or urban-rural economic dynamics (negative growth, youth out-migrations, etc).\nwages %\u0026gt;% filter(!(str_detect(`ER Code_Code RE`, \u0026#34;^ER\\\\d{2}$\u0026#34;))) %\u0026gt;% #filter provincial results do not appear filter(`ER Code_Code RE` != \u0026#34;ER00\u0026#34;) %\u0026gt;% #remove national totals filter(!is.na(`Median wage_Salaire Median`)) %\u0026gt;% #remove mising filter(`Annual Wage Flag_Salaire annuel` \u0026lt; 1) %\u0026gt;% #remove annual salaries filter(`Median wage_Salaire Median` \u0026lt;= 15) %\u0026gt;% filter(PROV == \u0026#34;ON\u0026#34; \u0026amp; `ER Name_Nom RE` == \u0026#34;Northeast\u0026#34; | `ER Name_Nom RE` == \u0026#34;Northwest\u0026#34;) %\u0026gt;% ggplot(aes(reorder(`NOC Title`, -`Median wage_Salaire Median`), `Median wage_Salaire Median`, fill=`ER Name_Nom RE`)) + geom_col(alpha=0.7, fill=\u0026#34;#91AAB4\u0026#34;, show.legend = F) + coord_flip() + facet_wrap(~`ER Name_Nom RE`) + labs(title = \u0026#34;Which occupations are affected by changes in minimum wage?\u0026#34;, x = NULL, y = \u0026#34;median hourly wage\u0026#34;, subtitle = \u0026#34;Northern Ontario Occupations by Median Hourly Wage\u0026#34;, caption = \u0026#34;Source: Wage data available via Open Data \\n http://open.canada.ca/data/en/dataset/adad580f-76b0-4502-bd05-20c125de9116\u0026#34;) + theme_ipsum_rc(base_family=\u0026#34;Roboto\u0026#34;, grid = \u0026#34;X\u0026#34;) \nLooks like a lot of jobs in the service sector. These jobs are important in the North so it will be interesting to see if the wage changes put these jobs at risk, or whether the additional purchasing power helps the bolster the service sector altogether.\nImpacts on communities We can also check what proportion of occupations have hourly wages that will be affected by the change in minimum wage. It\u0026rsquo;s interesting to look by community to see where Northern Ontario fits.\nwages %\u0026gt;% filter(!is.na(`Median wage_Salaire Median`)) %\u0026gt;% filter(!(str_detect(`ER Code_Code RE`, \u0026#34;^ER\\\\d{2}$\u0026#34;))) %\u0026gt;% #filter provincial results do not appear filter(`ER Code_Code RE` != \u0026#34;ER00\u0026#34;) %\u0026gt;% #remove national totals filter(`Annual Wage Flag_Salaire annuel` \u0026lt; 1) %\u0026gt;% #remove annual salaries filter(PROV == \u0026#34;ON\u0026#34;) %\u0026gt;% mutate(low_wage = case_when( `Median wage_Salaire Median` \u0026lt;= 14 ~ 1, TRUE ~ 0 )) %\u0026gt;% group_by(`ER Name_Nom RE`) %\u0026gt;% summarise(total_occupations = n_distinct(NOC_CNP), total_low_wage = sum(low_wage)) %\u0026gt;% mutate(prop_low_wage = total_low_wage / total_occupations) %\u0026gt;% ggplot(aes(reorder(`ER Name_Nom RE`, prop_low_wage), prop_low_wage)) + geom_col(alpha=0.7, fill=\u0026#34;#91AAB4\u0026#34;) + coord_flip() + scale_y_percent() + labs(title = \u0026#34;Where does the change in minimum wage affect Ontario communities most?\u0026#34;, x = NULL, y = \u0026#34;% of occupations with median wages \u0026lt; $14/hr\u0026#34;, subtitle = \u0026#34;Proportion of Occupations with Median Wage \u0026lt; $14/hr by Ontario Community\u0026#34;, caption = \u0026#34;Source: Wage data available via Open Data \\n http://open.canada.ca/data/en/dataset/adad580f-76b0-4502-bd05-20c125de9116\u0026#34;) + theme_ipsum_rc(base_family=\u0026#34;Roboto\u0026#34;, grid = \u0026#34;X\u0026#34;) \nOver 12 percent of occupations in the London area will be affected by the change in minimum wage. I wonder what kinds of effects the change will have on these smaller economies. Hopefully the feds update this dataset next year.\n","href":"/post/minwage/","title":"Minimum Wage Changes in Ontario"},{"content":" Google\u0026rsquo;s BigQuery has some interesting public datasets and luckily there\u0026rsquo;s an R package that makes interacting with the data extremely easy. The bigrquery library let\u0026rsquo;s you use SQL or dplyr statements to query the data which is super helpful.\nSimple Query I took a look at the data from the US Census Bureau‚Äôs International dataset which provides projections on population indicators. You need to create a projectid in the bigquery interface before you start.\nlibrary(tidyverse) library(hrbrthemes) library(bigrquery) project \u0026lt;- \u0026#34;YOUR_PROJECT_ID\u0026#34; sql \u0026lt;- \u0026#34;SELECT * FROM [bigquery-public-data:census_bureau_international.birth_death_growth_rates]\u0026#34; rawdata \u0026lt;- query_exec(sql, project = project) That will load the dataframe into your environment for analysis or visualizations.\nrawdata %\u0026gt;% select(Country = country_name, Year = year, `Growth Rate` = growth_rate) %\u0026gt;% filter(Country %in% c(\u0026#39;Canada\u0026#39;, \u0026#39;United States\u0026#39;)) %\u0026gt;% filter(Year \u0026gt; 2010) %\u0026gt;% ggplot(aes(x=Year, y=`Growth Rate`, group=Country)) + geom_line(aes(color=Country), size=0.8) + theme_ipsum_rc() + labs(y=\u0026#34;Growth Rate Percentage\u0026#34;, title=\u0026#34;Population Growth Rate Over Time\u0026#34;, caption=\u0026#34;Source: US Census Bureau\u0026#34;) ","href":"/post/bigquery/","title":"Using R with Google BigQuery"},{"content":"","href":"/tags/bigquery/","title":"bigquery"},{"content":"The 2016 Census has a lot of useful data to be examined. Luckily, there\u0026rsquo;s a great R package cancensus that let\u0026rsquo;s you access and map the data easily.\nYou can use get_census to download the table and geographic features you need.\nsault_income \u0026lt;- get_census(dataset=\u0026#39;CA16\u0026#39;, regions=list(CMA=\u0026#34;35590\u0026#34;), vectors=\u0026#34;v_CA16_2397\u0026#34;, level=\u0026#39;DA\u0026#39;, quiet = TRUE, geo_format = \u0026#39;sf\u0026#39;, labels = \u0026#39;short\u0026#39;) The dataframe is ready to be mapped using ggplot or leaflet if you want to be interactive.\nbins \u0026lt;- c(0, 25000,50000, 75000, 100000, 125000,Inf) pal \u0026lt;- colorBin(\u0026#34;RdYlBu\u0026#34;, domain = sault_income$v_CA16_2397, bins = bins) saultmap \u0026lt;- leaflet(sault_income) %\u0026gt;% addProviderTiles(providers$CartoDB.Positron) %\u0026gt;% addPolygons(fillColor = ~pal(v_CA16_2397), color = \u0026#34;white\u0026#34;, weight = 1, opacity = 1, fillOpacity = 0.55) %\u0026gt;% addLegend(\u0026#34;bottomright\u0026#34;, pal = pal, values = ~sault_income$v_CA16_2397, title = \u0026#34;Total Household Income\u0026#34;, labFormat = labelFormat(prefix = \u0026#34;$\u0026#34;), opacity = 1 ) %\u0026gt;% setView(lng = -84.346090, lat = 46.521858, zoom = 12)  ","href":"/post/censusmap/","title":"Mapping 2016 Census Data"},{"content":" Algoma Public Health is the public health agency in my area that inspects restaurants to ensure they are abiding by all the relevant food safety legislation. They are also nice enough to publish their restaurant health inspection reports online for anyone to review.\nI searched for a few restaurants that I frequent (phew Fratellis is safe!) but then I wanted to know which restaurants had the most health infractions?\nTheir website isn\u0026rsquo;t setup to answer that kind of question. Each inspection report is published as a unique page on their website which makes aggregating and comparing difficult.\nI used rvest to scrape the URLs of all the reports APH published. Then I scraped the contents of the reports so that I could create a dataset that would allow me to aggregate and compare the results (the dataset and code available here.)\nRestaurants with the most infractions Of the 90% of restaurants who received three visits, here are the top 5 in terms of total number of infractions:\nSurprising results. Upper Deck has some particularly bad health infractions.\nBut that got me thinking\u0026ndash;not all infractions are equal. Some are minor and are corrected onsite. Some are more serious and others still are downright strange. Let\u0026rsquo;s take a closer look.\nNumber of infractions Here are the top 10 infractions by frequency, meaning these infractions appear most often in the dataset.\nStranger Infractions The infractions that don\u0026rsquo;t appear frequently are also quite interesting. Here are infractions that only appear once in the dataset, but leave me with more questions than answers.\n   Restaurant Address Date Infraction     Juicy Beatz \u0026amp; Healthy Eatz 235 McNabb Street 2017-08-23 Food handler hygiene   Pauline\u0026rsquo;s Place 923 Queen Street 2017-11-28 Only Grade A or B eggs permitted   Queen West Variety 602 Queen Street 2016-12-16 Exclusion of live animals on the premises, subject to exemptions   Roberta Bondar Pavilion Serving Kitchens 65 Foster Dr 2016-08-30 No room with food used for sleeping purposes   Teen Challenge Kitchen 1446 Great Northern Road 2016-12-13 Uninspected meats obtained through hunting: only for custom cutting, wash/rinse/sanitize equipment after use as prescribed    Questions that come to mind:\n who\u0026rsquo;s sleeping in the Pavilion? did the Teen Challenge involve catching your meal? what kind of animals are hanging out in Queen West Variety? how does one tell the grade of eggs? Can you do it just by looking?  What does this data tell us? Not too much really :)\nI hope you enjoyed this peek behind the health inspection curtain. The dataset and code are available here. If you have any questions or comments, please feel free to get in touch.\n","href":"/post/resto/","title":"Scraping Restaurant Health Inspections"},{"content":"","href":"/tags/web-scraping/","title":"web scraping"},{"content":"At work, I\u0026rsquo;m always looking for a list of National Occupation Codes and their descriptions. I realized I can probably scrape this information faster than I can find it on my team\u0026rsquo;s network drive thanks to rvest and the tidyverse.\nLibraries:\nlibrary(tidyverse) # make tidy library(rvest) # scrape data library(knitr) # make a table Read in the appropriate list of NOCs:\nnocs \u0026lt;- read_html(\u0026#34;http://noc.esdc.gc.ca/English/NOC/QuickSearch.aspx?ver=16\u0026amp;val65=*\u0026#34;) Parse the HTML into a list then a file:\nnocs %\u0026gt;% html_nodes(\u0026#34;.NoBulletWithLessPadding a\u0026#34;) %\u0026gt;% html_text() %\u0026gt;% tibble() %\u0026gt;% # turn it into a dataframe object separate(\u0026#34;.\u0026#34;, into=c(\u0026#34;code\u0026#34;, \u0026#34;desc\u0026#34;), sep=4) %\u0026gt;% #seperate the code from the desc top_n(15) %\u0026gt;% # show only first 15 kable() # make a nice table    code desc     0912 Utilities managers   2153 Urban and land use planners   2175 Web designers and developers   2282 User support technicians   3114 Veterinarians   4011 University professors and lecturers   6345 Upholsterers   7237 Welders and related machine operators   7373 Water well drillers   7442 Waterworks and gas maintenance workers   7532 Water transport deck and engine room crew   8231 Underground production and development miners   9243 Water and waste treatment plant operators   9437 Woodworking machine operators   9442 Weavers, knitters and other fabric making occupations    Voila! use write_csv to export to a file.\n","href":"/post/noc-noc/","title":"Using rvest to scrape National Occupation Codes"},{"content":"","href":"/tags/noc/","title":"noc"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/config/","title":"Configuration"},{"content":"","href":"/tags/og/","title":"Opengraph"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/series/","title":"Series"}]
